{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd8e735",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CrossValidator로-교차검증-및-파라미터-튜닝-수행\" data-toc-modified-id=\"CrossValidator로-교차검증-및-파라미터-튜닝-수행-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CrossValidator로 교차검증 및 파라미터 튜닝 수행</a></span></li><li><span><a href=\"#Pipeline-클래스와-결합하기\" data-toc-modified-id=\"Pipeline-클래스와-결합하기-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pipeline 클래스와 결합하기</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c449c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+-----+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|label|\n",
      "+-----------------+----------------+-----------------+----------------+-----+\n",
      "|              5.1|             3.5|              1.4|             0.2|    0|\n",
      "|              4.9|             3.0|              1.4|             0.2|    0|\n",
      "|              4.7|             3.2|              1.3|             0.2|    0|\n",
      "|              4.6|             3.1|              1.5|             0.2|    0|\n",
      "|              5.0|             3.6|              1.4|             0.2|    0|\n",
      "+-----------------+----------------+-----------------+----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "\n",
    "iris_pdf = pd.DataFrame(iris_data, columns=iris.feature_names)\n",
    "iris_pdf['label'] = iris_label\n",
    "\n",
    "# convert pandas df to spark df\n",
    "iris_sdf = spark.createDataFrame(iris_pdf)\n",
    "iris_sdf.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61545811",
   "metadata": {},
   "source": [
    "## CrossValidator로 교차검증 및 파라미터 튜닝 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cddf46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# 1. 데이터 분할\n",
    "train, test = iris_sdf.randomSplit(weights=[0.8, 0.2], seed=42)\n",
    "\n",
    "# 2. Feature Vectorization\n",
    "columns = train.columns[:-1]\n",
    "vec_assembler = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "\n",
    "train_vec = vec_assembler.transform(train)\n",
    "test_vec = vec_assembler.transform(test)\n",
    "\n",
    "# 3. 모델 정의\n",
    "dt_clf = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "# 4. 튜닝할 하이퍼파라미터 grid 정의\n",
    "param_grid = ParamGridBuilder().addGrid(dt_clf.maxDepth, [5, 10]) \\\n",
    "                               .addGrid(dt_clf.minInstancesPerNode, [3, 10]) \\\n",
    "                               .build()\n",
    "\n",
    "# 5. 교차검증 수행하면서 측정할 메트릭 정의\n",
    "cv_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "# 6. CV 객체 정의(모델, 파라미터 grid, 메트릭, 폴드 수 설정)\n",
    "cv = CrossValidator(estimator=dt_clf, estimatorParamMaps=param_grid, evaluator=cv_evaluator, numFolds=3)\n",
    "\n",
    "# fit 메소드로 하이퍼파라미터 튜닝 및 교차검증 수행 -> 모델 객체 반환(기본적으로 최적의 파라미터로 refit 됨)\n",
    "cv_model = cv.fit(train_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "106c14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_result_pdf(cv_model):\n",
    "    params = [{k.name: v for k, v in c.items()} for c in cv_model.getEstimatorParamMaps()]\n",
    "    result_df = pd.DataFrame({'params': params,\n",
    "                             'evaluation_result': cv_model.avgMetrics})\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73da8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 학습된 cv_model 객체로 테스트 데이터에 대해 예측!\n",
    "test_pred = cv_model.transform(test_vec)\n",
    "\n",
    "test_evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                            predictionCol='prediction',\n",
    "                                            metricName='accuracy')\n",
    "test_acc = test_evaluator.evaluate(test_pred)\n",
    "print('Test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796fa02",
   "metadata": {},
   "source": [
    "## Pipeline 클래스와 결합하기\n",
    "- 총 2가지 방법으로 가능\n",
    "- 파이프라인으로 묶은 후, 이를 CrossValidator에 집어넣기\n",
    "- CrossValidator까지 과정을 스테이지로 해서 파이프라인으로 집어넣기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "052bf448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 교차검증 및 튜닝 완료 ######\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 방법\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 1. Train, Test 분할\n",
    "train, test = iris_sdf.randomSplit(weights=[0.8, 0.2], seed=42)\n",
    "\n",
    "# 2. Feature Vectorization Stage 생성\n",
    "columns = train.columns[:-1]\n",
    "stage_1 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "\n",
    "# 3. 모델 stage 생성\n",
    "stage_2 = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "# 4. 2번,3번 파이프라인 생성\n",
    "pipeline = Pipeline(stages=[stage_1, stage_2])\n",
    "\n",
    "# 5. 파라미터 grid 생성\n",
    "param_grid = ParamGridBuilder().addGrid(stage_2.maxDepth, [5, 12]) \\\n",
    "                               .addGrid(stage_2.minInstancesPerNode, [3, 8]) \\\n",
    "                               .build()\n",
    "# 6. evaluator 생성\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "# 7. CV 객체 생성\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# 8. 학습 및 교차검증, 파라미터 튜닝 수행\n",
    "cv_model = cv.fit(train)\n",
    "print('###### 교차검증 및 튜닝 완료 ######')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9355c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대해 수행\n",
    "test_pred = cv_model.transform(test)\n",
    "test_eval = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                             predictionCol='prediction',\n",
    "                                             metricName='accuracy')\n",
    "test_acc = test_eval.evaluate(test_pred)\n",
    "print('Test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598c327",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5592dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### 교차검증 및 튜닝 완료 ######\n"
     ]
    }
   ],
   "source": [
    "# 두번째 파이프라인 활용방법 -> 교차검증까지의 단계를 파이프라인으로 넣기\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 데이터 분할\n",
    "train, test = iris_sdf.randomSplit([0.7, 0.3], seed=43)\n",
    "\n",
    "columns = train.columns[:-1]\n",
    "# 하나의 스테이지 생성\n",
    "stage_1 = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "\n",
    "# 하나의 스테이지(모델, 파라미터 튜닝-CV 까지 동시에 수행) 생성\n",
    "dt_clf = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "param_grid = ParamGridBuilder().addGrid(dt_clf.maxDepth, [5, 10]) \\\n",
    "                               .addGrid(dt_clf.minInstancesPerNode, [10, 20]) \\\n",
    "                               .build()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                             predictionCol='prediction',\n",
    "                                             metricName='accuracy')\n",
    "stage_cv = CrossValidator(estimator=dt_clf, estimatorParamMaps=param_grid,\n",
    "                         evaluator=evaluator)\n",
    "\n",
    "# 파이프라인 생성\n",
    "pipeline = Pipeline(stages=[stage_1, stage_cv])\n",
    "\n",
    "# fit\n",
    "pipeline_model = pipeline.fit(train)\n",
    "print('###### 교차검증 및 튜닝 완료 ######')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10c836ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9148936170212766\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대해 수행\n",
    "test_pred = pipeline_model.transform(test)\n",
    "\n",
    "test_evaluator = MulticlassClassificationEvaluator(labelCol='label',\n",
    "                                                  predictionCol='prediction',\n",
    "                                                  metricName='accuracy')\n",
    "test_acc = test_evaluator.evaluate(test_pred)\n",
    "print('Test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d7bb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76259a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainValidationSplit 이용하기\n",
    "# -> 단, 학습 데이터 비율을 지정(맨 끝이 무조건 검증 데이터셋으로 떼놓음)\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "\n",
    "vec_assembler = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "train_vec = vec_assembler.transform(train)\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=dt_clf, estimatorParamMaps=param_grid,\n",
    "                          evaluator=evaluator)\n",
    "tvs_model = tvs.fit(train_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ea81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
