# Problem 1
- ``train_sparse.tsv``, ``test_sparse.tsv`` 데이터를 활용한 다중 분류 예측
## 모델 학습 실행 방법
## 모델 예측 실행 방법
## Flask 웹 서버에서 예측 방법
## 분석 보고서
### 1. 데이터 탐색 및 피쳐 추출
(1) **종속변수**(``label``)
- 범주형 변수이기 때문에 클래스의 분포도 확인<br><br>
<img width="482" alt="스크린샷 2021-11-18 오후 5 31 13" src="https://user-images.githubusercontent.com/54783194/142379662-2d4b409c-3012-45b6-ba1f-5a48103e5a41.png"><br>
- 확인 결과, 클래스 불균형 발견
  - 모델 개발 단계에서 성능 검증 시 클래스 분포를 고려해 학습/검증 데이터 분할 수행해야 함
  - 오버샘플링을 통해 클래스 균형 상태로 만들어준 후 모델의 성능 검증 시도

(2) **날짜 변수**
- 여기서 날짜변수란, 아래와 같이 필드의 값에 ``a_date`` 또는 ``c_date`` 문자열이 들어간 필드 2개를 의미<br><br>
![스크린샷 2021-11-18 오후 4 52 31](https://user-images.githubusercontent.com/54783194/142374460-974680be-f083-476b-b639-dc35a96874e2.png)
- 광고 카테고리 유형별에 따라 시간적인 특성이 있을 것으로 예상하여 해당 필드의 값을 ``pandas.datetime`` 형태로 전처리 수행 후 종속변수와 통계적 검정 수행
  - 변환된 ``datetime`` 형태의 필드로부터 해당 시간의 ``연도(year)``, ``월(month)``, ``시간대(hour)`` 을 파생변수로 생성
- ``a_date`` 또는 ``c_date`` 필드로부터 생성한 파생변수들(``연도(year)``, ``월(month)``, ``시간대(hour)``) 과 종속변수(``label``)과의 관계 파악을 위해 통계적 검정 수행
  - 두 범주형 변수 간의 관계 파악을 해야하고 종속변수 유형이 하나의 모집단에 속하기 때문에 **독립성 검정**을 위해 카이제곱 통계적 검정 수행
  - 카이제곱 통계적 검정에서 **``p-value < 0.05``** 라면 두 범주형 변수 간의 관계가 있음을 의미<br><br>
  <img width="456" alt="스크린샷 2021-11-18 오후 5 37 03" src="https://user-images.githubusercontent.com/54783194/142380484-feb2a531-7828-43be-9db0-8d8a24432499.png"><br>
  - 위와 같이 통계적 검정 결과, 생성한 시간 관련 파생변수들 모두 종속변수에 따라 빈도차이가 존재하므로 종속변수와 관계가 있음을 알 수 있음
  - 따라서, 예측 모델 개발 시, Feature Engineering 으로 사용하기로 결정

(3) **다른 주어진 익명의 범주형 변수들**
- 먼저, 주어진 다른 변수들 중 아래 그림에서 ``ftr2``, ``ftr3``, ``ftr6``, ``ftr7`` 변수들과 종속변수 간의 관계 파악을 위해 동일하게 독립성 검정 수행
  - 여기서 피어슨 상관분석을 하지 않은 이유는 '과제 설명' 부분에서 필드 모두 문자열 형태의 데이터라고 했기 때문. 모두 문자열 데이터라는 것은 모두 범주형 데이터임을 의미
- ``ftr2``, ``ftr3``, ``ftr6``, ``ftr7`` 변수들과 종속변수 간의 독립성 검정 수행 결과는 아래와 같음<br><br>
<img width="508" alt="스크린샷 2021-11-18 오후 5 46 18" src="https://user-images.githubusercontent.com/54783194/142381821-0751b55a-7eb3-492f-a179-acc6cd86bd87.png"><br>
- 통계적 검정 결과, 다른 익명의 변수들도 모두 종속변수와 관계가 있다고 판단
- 따라서, 예측 모델 개발 시, 해당 변수들 모두 변수로 활용하기로 결정

(4) **Sparse한 익명의 변수**
- 여기서 'Sparse한 익명의 변수'란, 아래 그림에서 ``ftr1``을 의미<br>
<img width="466" alt="스크린샷 2021-11-18 오후 5 50 12" src="https://user-images.githubusercontent.com/54783194/142382450-402af6c1-3084-4568-b180-c5c7d7d4b75b.png"><br>
- 해당 변수에 들어있는 숫자들이 무엇을 의미하는 것인지 파악이 불가
- 광고 내용 텍스트의 단어들을 사전에 정의한 Vocabulary 범위의 인덱스로 매핑한 변수라고 생각해 0을 모두 제거
- 0 이외의 값들에 대해 벡터화 후 코사인 유사도를 계산하려 했으나 약 ``(10만, 1만 5천)`` 형상의 Sparse한 행렬이 계산됨
- 이러한 너무 Sparse한 행렬을 변수로 활용한다면 차원의 저주에 걸릴 뿐만 아니라 모델의 오버피팅을 발생시킬 가능성이 농후하기 때문에 **과감히 제거**
### 2. 모델 선정
- 모든 변수가 범주형 변수이기 때문에 변수 값들을 Normalization 해서는 안 됨
- 따라서, 변수 값들을 Normalization 하지 않고 예측을 해야 하므로 **Tree 기반 모델**을 선정
- 클래스 불균형 문제를 해소하기 위해 다음과 같은 방법을 사용해 후보 모델들의 성능 검증
  - 소수 클래스에 속하는 데이터의 거리 주변에 원본 데이터와 동일하지 않으면서 소수 클래스에 속하는 가상의 데이터를 생성(K-NN 알고리즘 사용해 샘플링하는 기법)
  - 클래스 유형 별 개수를 고려해 학습, 검증 데이터를 분할하는 ``Stratified K-fold`` 교차검증 방법 수행(2만개 데이터씩 총 5번 검증 수행)
- 사용된 평가 지표: ``정확도(Accuracy)``, ``정밀도(Precision)``, ``재현율(Recall)``, ``F1-score``, ``AUC``
- 하단의 지표는 5번의 교차 검증 수행한 결과

|Model|Train Accuracy|Valid Accuracy|Precision|Recall|F1-score|AUC|Training time|
|---|---|---|---|---|---|---|---|
|**Decision Tree**|99.9%|98.8%|0.98|0.98|0.98|0.99|**2.2초**|
|Random Forest|99.9%|99.5%|0.99|0.99|0.99|0.99|52.5초|
|XGBoost|99.9%|98.7%|0.98|0.98|0.98|0.99|383.3초|
|Light GBM|17.2%|17.2%|0.25|0.17|0.15|0.56|27.2초|
- 위 표의 ``Training time``인 학습 시간은 오버샘플링 한 후인 약 64만 개의 데이터 학습 시간을 의미
- ``Light GBM``을 제외한 모든 모델들의 성능이 매우 좋음
- 하지만 모델 학습 시간에 있어서 매우 큰 차이가 발생
- 따라서, 가장 빠른 성능을 보이는 **``Decision Tree``** 로 최종 모델 선정
